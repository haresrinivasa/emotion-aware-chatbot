# ğŸ¤– Emotion-Aware Chatbot

A real-time, webcam-integrated chatbot that detects human emotions using facial expressions 
and responds **empathetically**. This project combines computer vision, deep learning, and 
natural language processing to create a more emotionally intelligent conversational experience.

---

## ğŸ’¡ Project Overview

This Emotion-Aware Chatbot captures a user's facial expression via webcam, detects their emotional state using a pre-trained deep learning model, and generates a contextually appropriate response. It's designed to demonstrate how AI can be used to build emotionally responsive systems, with potential applications in mental health support, customer service, and human-computer interaction.

---

## ğŸ¯ Key Features

- ğŸ“· **Webcam Integration**: Captures real-time facial images.
- ğŸ¤– **Emotion Detection**: Uses the `FER` (Facial Expression Recognition) library with MTCNN for accurate emotion classification.
- ğŸ’¬ **Empathetic Responses**: Generates human-like responses tailored to the detected emotion.
- ğŸ§© **Modular Design**: Clean separation of concerns across camera, emotion detection, and chatbot logic.

## ğŸ› ï¸ Tech Stack

- **Language**: Python 3.11
- **Libraries**:
  - `OpenCV` â€“ for webcam access and image capture
  - `FER` â€“ for facial emotion recognition
  - `TensorFlow` â€“ backend for emotion detection model
  - `Keras` â€“ model loading and inference
- **Environment**: Virtualenv / VS Code Dev Container

---

## ğŸ§  How It Works
1. **Capture**: The webcam captures a live image when the user presses q.

2. **Detect**: The image is passed to the FER model to identify the dominant emotion.

3. **Respond**: A chatbot message is generated based on the detected emotion.

---

## ğŸ”„ Version History

- **First Build**: 
  - CLI based application where static image was loaded to test the FER Model capabilities.

- **Second Build**: 
  - Simple Web interface where webcam of the user is used and real time emotion is captured!

---
## ğŸ“Œ Example Output
<details>
  <summary><strong>FIRST BUILD</strong></summary>
  <br> On Local <img src=".images/first_build.png" alt="First Build Output"/><br>
  <br> On Azure <img src=".images/first_build_on_azure.png" alt="First Build Output on Azure"/> <br>
</details> <br>
<details>
  <summary><strong>SECOND BUILD</strong></summary>
  <br> On Local <img src=".images/second_build.png" alt="Second Build Output"/><br>
  <br>
  <pre>
  ğŸ” Flow Summary
  [User] â†’ clicks "Capture Emotion"
    â†“
  [Frontend JS] â†’ captures webcam frame â†’ converts to base64 â†’ sends to backend
    â†“
  [Backend] â†’ decodes image â†’ detects emotion â†’ generates response
    â†“
  [Frontend] â†’ displays emotion, confidence, and chatbot reply
  </pre>
</details>

---

## ğŸ“ Project Structure
<details>
  <summary><strong>FIRST BUILD</strong></summary>
  <pre>
  ğŸ“ emotion-aware-chatbot/
  â”œâ”€â”€ ğŸ“‚ .devcontainer/              # âš™ï¸ Dev container setup for GitHub Codespaces or VS Code
  â”‚   â””â”€â”€ ğŸ“„ devcontainer.json       #    - Defines the container environment
  â”‚
  â”œâ”€â”€ ğŸ“‚ camera/                     # ğŸ“¸ Webcam utilities
  â”‚   â””â”€â”€ ğŸ“„ webcam.py               #    - Captures live video and extracts facial images
  â”‚
  â”œâ”€â”€ ğŸ“‚ chatbot/                    # ğŸ¤– Chatbot logic
  â”‚   â””â”€â”€ ğŸ“„ empathetic_bot.py       #    - Returns emotion-specific responses
  â”‚
  â”œâ”€â”€ ğŸ“‚ emotion/                    # ğŸ˜¶ Emotion detection module
  â”‚   â””â”€â”€ ğŸ“„ emotion_detector.py     #    - Uses FER to detect emotions from facial images
  â”‚
  â”œâ”€â”€ ğŸ“„ app.py                      # ğŸš€ Main entry point that ties all modules together
  â”œâ”€â”€ ğŸ“„ Dockerfile                  # ğŸ³ Docker configuration for containerizing the app
  â”œâ”€â”€ ğŸ“„ requirements.txt            # ğŸ“¦ Python dependencies
  â”œâ”€â”€ ğŸ“„ .gitignore                  # ğŸš« Git ignore rules
  â”œâ”€â”€ ğŸ“„ .dockerignore               # ğŸš« Docker ignore rules
  â””â”€â”€ ğŸ“„ README.md                   # ğŸ“˜ Project documentation (you are reading this now ğŸ˜œ)
  </pre>
</details>
<br>
<details>
  <summary><strong>SECOND BUILD</strong></summary>
  <pre>
  ğŸ“ emotion-aware-chatbot/
  â”œâ”€â”€ ğŸ“‚ backend/                   # ğŸ”— Integration logic
  â”‚   â””â”€â”€ ğŸ“„ integration.py         #    - Connects webcam, emotion detection, and chatbot
  â”‚
  â”œâ”€â”€ ğŸ“‚ camera/                    # ğŸ“¸ Webcam utilities
  â”‚   â””â”€â”€ ğŸ“„ webcam.py              #    - Decodes base64 webcam images
  â”‚
  â”œâ”€â”€ ğŸ“‚ emotion/                   # ğŸ˜¶ Emotion detection module
  â”‚   â””â”€â”€ ğŸ“„ emotion_detector.py    #    - Detects emotions using FER or ML model
  â”‚
  â”œâ”€â”€ ğŸ“‚ chatbot/                   # ğŸ¤– Chatbot logic
  â”‚   â””â”€â”€ ğŸ“„ empathetic_bot.py      #    - Returns emotion-specific responses
  â”‚
  â”œâ”€â”€ ğŸ“‚ docs/                      # ğŸŒ Frontend assets
  â”‚   â”œâ”€â”€ ğŸ“„ index.html             #    - Refactored with Material Web Components
  â”‚   â”œâ”€â”€ ğŸ“„ style.css              #    - Material Design-inspired styling
  â”‚   â””â”€â”€ ğŸ“„ script.js              #    - Webcam capture and backend communication
  â”‚
  â”œâ”€â”€ ğŸ“„ app.py                     # ğŸš€ Flask app entry point
  â”œâ”€â”€ ğŸ“„ Dockerfile                 # ğŸ³ Docker configuration
  â”œâ”€â”€ ğŸ“„ requirements.txt           # ğŸ“¦ Python dependencies
  â”œâ”€â”€ ğŸ“„ .gitignore                 # ğŸš« Git ignore rules
  â”œâ”€â”€ ğŸ“„ .dockerignore              # ğŸš« Docker ignore rules
  â””â”€â”€ ğŸ“„ README.md                  # ğŸ“˜ Project documentation (you are reading this now ğŸ˜œ)
  </pre>
</details>

---

## ğŸš€ Getting Started
### ğŸ³ Recommended: Run with Docker
<details> 
<summary><strong>View Steps</strong></summary> 
<br> 

```bash
### 1. Clone the repository
git clone https://github.com/haresrinivasa/emotion-aware-chatbot.git
cd emotion-aware-chatbot

### 2. Build the Docker image
docker build -t emotion-aware .

### 3. Run the application
docker run -it --rm emotion-aware
```
</details>

### ğŸ› ï¸ Optional: Run Locally Without Docker
<details> 
<summary><strong>View Steps</strong></summary> 
<br> 

``` bash
# 1. Create and activate a virtual environment
python -m venv first_build_env
source first_build_env/bin/activate  # On Windows: first_build_env\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Install system dependencies (Linux only)
sudo apt-get update && sudo apt-get install -y libgl1
sudo apt update
sudo apt install git-lfs
git lfs install

# 4. Run the application
python app.py
```
</details>

---

## ğŸ“« Developer Contact
balaji27venkatesh@gmail.com
